{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pytorch](../../../pytorch_logo_2018.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 中级篇（1）：卷积神经网络（Convolutional Neural Network）\n",
    "\n",
    ">参考代码\n",
    ">\n",
    ">**yunjey的 [pytorch tutorial系列](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/convolutional_neural_network/main.py)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备配置\n",
    "torch.cuda.set_device(1) # 这句用来设置pytorch在哪块GPU上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 超参数设置\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../../data/minist/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "# 测试数据集\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../../data/minist',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# 数据加载器\n",
    "# 训练数据 加载器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# 测试数据加载器\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义 卷积神经网络\n",
    "\n",
    ">参考阅读\n",
    ">\n",
    ">卷积层的计算细节可以看这篇\n",
    ">[CNN中卷积层的计算细节](https://zhuanlan.zhihu.com/p/29119239)\n",
    ">\n",
    ">更详细的介绍，包括池化层的，可以看这篇\n",
    ">[卷积神经网络中的参数计算](https://www.cnblogs.com/hejunlin1992/p/7624807.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建卷积神经网络模型\n",
    "# 两个卷积层\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # 卷积层计算\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            #  批归一化\n",
    "            nn.BatchNorm2d(16),\n",
    "            #ReLU激活函数\n",
    "            nn.ReLU(),\n",
    "            # 池化层：最大池化\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    # 定义前向传播顺序\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化一个模型，并迁移至gpu\n",
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1262\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1282\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0826\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0521\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0899\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0369\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0278\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0228\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0493\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0382\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0487\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0127\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0319\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0355\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0438\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0626\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0343\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0376\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0093\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0098\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0054\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0814\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0385\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0334\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0192\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0192\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0238\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0186\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0142\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0101\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 注意模型在GPU中，数据也要搬到GPU中\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试并保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 切换成评估测试模式\n",
    "# 这是因为在测试时，与训练时的dropout和batch normalization的操作是不同的\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.75 %\n"
     ]
    }
   ],
   "source": [
    "# 节省计算资源，不去计算梯度\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  保存模型\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何用自己的图片和模型进行测试（单张）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "\n",
    "#resize功能\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 彩图转灰度\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 读取图像\n",
    "srcPath = '3.png'\n",
    "src = mpimg.imread(srcPath)# 读取和代码处于同一目录下的 图片\n",
    "# 此时 lena 就已经是一个 np.array 了，可以对它进行任意处理\n",
    "# 原图大小\n",
    "print(src.shape) \n",
    "\n",
    "plt.imshow(src) # 显示图片\n",
    "plt.axis('off') # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gray = rgb2gray(src)    #转灰度\n",
    "\n",
    "gray_new_sz = misc.imresize(gray, (28,28) )# 第二个参数如果是整数，则为百分比，如果是tuple，则为输出图像的尺寸\n",
    "print(gray_new_sz.shape)\n",
    "plt.imshow(gray_new_sz, cmap='Greys_r')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为（B,C,H,W）大小\n",
    "image = gray_new_sz.reshape(-1,1,28,28)\n",
    "\n",
    "# 转换为torch tensor\n",
    "image_tensor = torch.from_numpy(image).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "# 调用模型进行评估\n",
    "# model.eval() \n",
    "output = model(image_tensor.to(device))\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "pre = predicted.cpu().numpy()\n",
    "print(pre) # 查看预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 友情Tip：查看Pytorch跑在哪块GPU上\n",
    "\n",
    "遇到`cuda runtime error: out of memory`时，可以查看一下跑在哪块GPU上了。\n",
    "\n",
    "然后用`nvidia-smi`看一下是不是GPU被占用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这一段可以用来查看当前GPU的情况\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
