{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pytorch](../../../pytorch_logo_2018.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 番外篇：Pytorch中的TensorBoard（TensorBoard in PyTorch）\n",
    "\n",
    ">参考代码\n",
    ">\n",
    ">**yunjey的 [pytorch tutorial系列](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard相关资料\n",
    "\n",
    "TensorBoard是Tensorflow官方推出的可视化工具。\n",
    "\n",
    ">**官方介绍**\n",
    ">\n",
    ">[TensorBoard: Visualizing Learning](https://www.tensorflow.org/guide/summaries_and_tensorboard)\n",
    ">\n",
    ">[TensorBoard实践介绍（2017年TensorFlow开发大会）](https://www.youtube.com/watch?v=eBbEDRsCmv4&feature=youtu.be)\n",
    "\n",
    ">**相关博客**\n",
    ">\n",
    ">[Tensorflow的可视化工具Tensorboard的初步使用](https://blog.csdn.net/sinat_33761963/article/details/62433234)\n",
    ">\n",
    ">[TensorFlow教程 4 Tensorboard 可视化好帮手](https://blog.csdn.net/u012052268/article/details/75394077)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 实现\n",
    "\n",
    "在这次的代码里，是通过简单的神经网络实现一个MINIST的分类器，并且通过**TensorBoard**实现训练过程的可视化。\n",
    "\n",
    "在训练阶段，通过`scalar_summary`画出损失和精确率，通过`image_summary`可视化训练的图像。\n",
    "\n",
    "另外，使用`histogram_summary`可视化神经网络的参数的权重和梯度值。\n",
    "\n",
    "*需要安装的 package*\n",
    "- tensorflow\n",
    "- torch\n",
    "- torchvision\n",
    "- scipy\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOG功能实现（Logger类）\n",
    "\n",
    "基于TensorBoard，给Pytorch的训练提供保存训练信息的接口。\n",
    "\n",
    "Tensorboard可以记录与展示以下数据形式：\n",
    "- 标量Scalars \n",
    "- 图片Images \n",
    "- 音频Audio \n",
    "- 计算图Graph \n",
    "- 数据分布Distribution \n",
    "- 直方图Histograms \n",
    "- 嵌入向量Embeddings\n",
    "\n",
    "代码中实现了标量Scalar、图片Image、直方图Histogram的保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "try:\n",
    "    from StringIO import StringIO  # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO         # Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "         # 创建一个指向log文件夹的summary writer\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        # 标量信息 日志\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "        # 图像信息 日志\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=img.shape[0],\n",
    "                                       width=img.shape[1])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        \n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "        # 直方图信息 日志\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values**2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型并训练（训练过程中输出日志）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备配置\n",
    "torch.cuda.set_device(1) # 这句用来设置pytorch在哪块GPU上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 数据集\n",
    "dataset = torchvision.datasets.MNIST(root='../../../data/minist', \n",
    "                                     train=True, \n",
    "                                     transform=transforms.ToTensor(),  \n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个全连接网络（含一个隐藏层）\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "model = NeuralNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建日志类，指定文件夹\n",
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/50000], Loss: 2.1946, Acc: 0.44\n",
      "Step [200/50000], Loss: 2.1081, Acc: 0.51\n",
      "Step [300/50000], Loss: 1.9934, Acc: 0.68\n",
      "Step [400/50000], Loss: 1.7980, Acc: 0.78\n",
      "Step [500/50000], Loss: 1.7040, Acc: 0.71\n",
      "Step [600/50000], Loss: 1.5549, Acc: 0.73\n",
      "Step [700/50000], Loss: 1.4596, Acc: 0.73\n",
      "Step [800/50000], Loss: 1.3418, Acc: 0.80\n",
      "Step [900/50000], Loss: 1.2599, Acc: 0.73\n",
      "Step [1000/50000], Loss: 1.1744, Acc: 0.78\n",
      "Step [1100/50000], Loss: 1.1137, Acc: 0.81\n",
      "Step [1200/50000], Loss: 1.0074, Acc: 0.85\n",
      "Step [1300/50000], Loss: 0.8924, Acc: 0.86\n",
      "Step [1400/50000], Loss: 0.9266, Acc: 0.84\n",
      "Step [1500/50000], Loss: 0.8485, Acc: 0.87\n",
      "Step [1600/50000], Loss: 0.8521, Acc: 0.82\n",
      "Step [1700/50000], Loss: 0.8131, Acc: 0.85\n",
      "Step [1800/50000], Loss: 0.6989, Acc: 0.86\n",
      "Step [1900/50000], Loss: 0.6134, Acc: 0.95\n",
      "Step [2000/50000], Loss: 0.7695, Acc: 0.83\n",
      "Step [2100/50000], Loss: 0.6143, Acc: 0.90\n",
      "Step [2200/50000], Loss: 0.6876, Acc: 0.84\n",
      "Step [2300/50000], Loss: 0.5857, Acc: 0.88\n",
      "Step [2400/50000], Loss: 0.6920, Acc: 0.82\n",
      "Step [2500/50000], Loss: 0.5285, Acc: 0.91\n",
      "Step [2600/50000], Loss: 0.4978, Acc: 0.88\n",
      "Step [2700/50000], Loss: 0.5947, Acc: 0.87\n",
      "Step [2800/50000], Loss: 0.5268, Acc: 0.85\n",
      "Step [2900/50000], Loss: 0.4872, Acc: 0.90\n",
      "Step [3000/50000], Loss: 0.5411, Acc: 0.89\n",
      "Step [3100/50000], Loss: 0.5166, Acc: 0.90\n",
      "Step [3200/50000], Loss: 0.4512, Acc: 0.87\n",
      "Step [3300/50000], Loss: 0.4630, Acc: 0.90\n",
      "Step [3400/50000], Loss: 0.4346, Acc: 0.90\n",
      "Step [3500/50000], Loss: 0.5625, Acc: 0.84\n",
      "Step [3600/50000], Loss: 0.4900, Acc: 0.87\n",
      "Step [3700/50000], Loss: 0.4563, Acc: 0.90\n",
      "Step [3800/50000], Loss: 0.3841, Acc: 0.92\n",
      "Step [3900/50000], Loss: 0.4031, Acc: 0.91\n",
      "Step [4000/50000], Loss: 0.5147, Acc: 0.88\n",
      "Step [4100/50000], Loss: 0.4474, Acc: 0.89\n",
      "Step [4200/50000], Loss: 0.4465, Acc: 0.85\n",
      "Step [4300/50000], Loss: 0.5455, Acc: 0.85\n",
      "Step [4400/50000], Loss: 0.3192, Acc: 0.91\n",
      "Step [4500/50000], Loss: 0.3269, Acc: 0.91\n",
      "Step [4600/50000], Loss: 0.4328, Acc: 0.87\n",
      "Step [4700/50000], Loss: 0.3868, Acc: 0.90\n",
      "Step [4800/50000], Loss: 0.3626, Acc: 0.90\n",
      "Step [4900/50000], Loss: 0.4579, Acc: 0.87\n",
      "Step [5000/50000], Loss: 0.3812, Acc: 0.92\n",
      "Step [5100/50000], Loss: 0.4121, Acc: 0.90\n",
      "Step [5200/50000], Loss: 0.3456, Acc: 0.88\n",
      "Step [5300/50000], Loss: 0.3297, Acc: 0.86\n",
      "Step [5400/50000], Loss: 0.3326, Acc: 0.93\n",
      "Step [5500/50000], Loss: 0.3313, Acc: 0.93\n",
      "Step [5600/50000], Loss: 0.2667, Acc: 0.93\n",
      "Step [5700/50000], Loss: 0.3221, Acc: 0.91\n",
      "Step [5800/50000], Loss: 0.3784, Acc: 0.90\n",
      "Step [5900/50000], Loss: 0.3969, Acc: 0.91\n",
      "Step [6000/50000], Loss: 0.3857, Acc: 0.88\n",
      "Step [6100/50000], Loss: 0.5209, Acc: 0.83\n",
      "Step [6200/50000], Loss: 0.3780, Acc: 0.89\n",
      "Step [6300/50000], Loss: 0.3143, Acc: 0.92\n",
      "Step [6400/50000], Loss: 0.2864, Acc: 0.93\n",
      "Step [6500/50000], Loss: 0.2920, Acc: 0.93\n",
      "Step [6600/50000], Loss: 0.2822, Acc: 0.93\n",
      "Step [6700/50000], Loss: 0.3647, Acc: 0.89\n",
      "Step [6800/50000], Loss: 0.4020, Acc: 0.89\n",
      "Step [6900/50000], Loss: 0.3046, Acc: 0.91\n",
      "Step [7000/50000], Loss: 0.2945, Acc: 0.92\n",
      "Step [7100/50000], Loss: 0.2468, Acc: 0.92\n",
      "Step [7200/50000], Loss: 0.3562, Acc: 0.89\n",
      "Step [7300/50000], Loss: 0.3864, Acc: 0.91\n",
      "Step [7400/50000], Loss: 0.3356, Acc: 0.88\n",
      "Step [7500/50000], Loss: 0.3885, Acc: 0.91\n",
      "Step [7600/50000], Loss: 0.2769, Acc: 0.95\n",
      "Step [7700/50000], Loss: 0.3207, Acc: 0.92\n",
      "Step [7800/50000], Loss: 0.4069, Acc: 0.90\n",
      "Step [7900/50000], Loss: 0.3654, Acc: 0.88\n",
      "Step [8000/50000], Loss: 0.3255, Acc: 0.91\n",
      "Step [8100/50000], Loss: 0.3344, Acc: 0.91\n",
      "Step [8200/50000], Loss: 0.3826, Acc: 0.89\n",
      "Step [8300/50000], Loss: 0.2105, Acc: 0.94\n",
      "Step [8400/50000], Loss: 0.3225, Acc: 0.92\n",
      "Step [8500/50000], Loss: 0.2647, Acc: 0.92\n",
      "Step [8600/50000], Loss: 0.3324, Acc: 0.92\n",
      "Step [8700/50000], Loss: 0.3442, Acc: 0.92\n",
      "Step [8800/50000], Loss: 0.3226, Acc: 0.90\n",
      "Step [8900/50000], Loss: 0.3488, Acc: 0.89\n",
      "Step [9000/50000], Loss: 0.2275, Acc: 0.90\n",
      "Step [9100/50000], Loss: 0.4575, Acc: 0.86\n",
      "Step [9200/50000], Loss: 0.3145, Acc: 0.92\n",
      "Step [9300/50000], Loss: 0.3080, Acc: 0.91\n",
      "Step [9400/50000], Loss: 0.2287, Acc: 0.95\n",
      "Step [9500/50000], Loss: 0.2993, Acc: 0.91\n",
      "Step [9600/50000], Loss: 0.4530, Acc: 0.87\n",
      "Step [9700/50000], Loss: 0.1822, Acc: 0.97\n",
      "Step [9800/50000], Loss: 0.3450, Acc: 0.89\n",
      "Step [9900/50000], Loss: 0.2560, Acc: 0.93\n",
      "Step [10000/50000], Loss: 0.2697, Acc: 0.94\n",
      "Step [10100/50000], Loss: 0.2988, Acc: 0.91\n",
      "Step [10200/50000], Loss: 0.3495, Acc: 0.92\n",
      "Step [10300/50000], Loss: 0.4134, Acc: 0.89\n",
      "Step [10400/50000], Loss: 0.3373, Acc: 0.88\n",
      "Step [10500/50000], Loss: 0.4549, Acc: 0.88\n",
      "Step [10600/50000], Loss: 0.2884, Acc: 0.93\n",
      "Step [10700/50000], Loss: 0.3823, Acc: 0.88\n",
      "Step [10800/50000], Loss: 0.3461, Acc: 0.87\n",
      "Step [10900/50000], Loss: 0.3744, Acc: 0.89\n",
      "Step [11000/50000], Loss: 0.2437, Acc: 0.94\n",
      "Step [11100/50000], Loss: 0.2320, Acc: 0.96\n",
      "Step [11200/50000], Loss: 0.3769, Acc: 0.88\n",
      "Step [11300/50000], Loss: 0.2432, Acc: 0.91\n",
      "Step [11400/50000], Loss: 0.1990, Acc: 0.92\n",
      "Step [11500/50000], Loss: 0.2715, Acc: 0.93\n",
      "Step [11600/50000], Loss: 0.3470, Acc: 0.88\n",
      "Step [11700/50000], Loss: 0.1974, Acc: 0.95\n",
      "Step [11800/50000], Loss: 0.3201, Acc: 0.91\n",
      "Step [11900/50000], Loss: 0.2347, Acc: 0.95\n",
      "Step [12000/50000], Loss: 0.2027, Acc: 0.95\n",
      "Step [12100/50000], Loss: 0.2058, Acc: 0.96\n",
      "Step [12200/50000], Loss: 0.1681, Acc: 0.96\n",
      "Step [12300/50000], Loss: 0.2309, Acc: 0.94\n",
      "Step [12400/50000], Loss: 0.2410, Acc: 0.92\n",
      "Step [12500/50000], Loss: 0.2456, Acc: 0.93\n",
      "Step [12600/50000], Loss: 0.4254, Acc: 0.86\n",
      "Step [12700/50000], Loss: 0.2732, Acc: 0.93\n",
      "Step [12800/50000], Loss: 0.2724, Acc: 0.94\n",
      "Step [12900/50000], Loss: 0.2342, Acc: 0.94\n",
      "Step [13000/50000], Loss: 0.2334, Acc: 0.93\n",
      "Step [13100/50000], Loss: 0.2379, Acc: 0.92\n",
      "Step [13200/50000], Loss: 0.2277, Acc: 0.94\n",
      "Step [13300/50000], Loss: 0.2049, Acc: 0.96\n",
      "Step [13400/50000], Loss: 0.2546, Acc: 0.95\n",
      "Step [13500/50000], Loss: 0.1957, Acc: 0.93\n",
      "Step [13600/50000], Loss: 0.2615, Acc: 0.91\n",
      "Step [13700/50000], Loss: 0.3025, Acc: 0.92\n",
      "Step [13800/50000], Loss: 0.3255, Acc: 0.92\n",
      "Step [13900/50000], Loss: 0.2769, Acc: 0.94\n",
      "Step [14000/50000], Loss: 0.2192, Acc: 0.97\n",
      "Step [14100/50000], Loss: 0.2660, Acc: 0.92\n",
      "Step [14200/50000], Loss: 0.2216, Acc: 0.93\n",
      "Step [14300/50000], Loss: 0.1977, Acc: 0.95\n",
      "Step [14400/50000], Loss: 0.3477, Acc: 0.88\n",
      "Step [14500/50000], Loss: 0.4106, Acc: 0.89\n",
      "Step [14600/50000], Loss: 0.1890, Acc: 0.95\n",
      "Step [14700/50000], Loss: 0.4205, Acc: 0.86\n",
      "Step [14800/50000], Loss: 0.2099, Acc: 0.93\n",
      "Step [14900/50000], Loss: 0.1090, Acc: 1.00\n",
      "Step [15000/50000], Loss: 0.2324, Acc: 0.93\n",
      "Step [15100/50000], Loss: 0.1638, Acc: 0.97\n",
      "Step [15200/50000], Loss: 0.2307, Acc: 0.94\n",
      "Step [15300/50000], Loss: 0.2562, Acc: 0.95\n",
      "Step [15400/50000], Loss: 0.2240, Acc: 0.95\n",
      "Step [15500/50000], Loss: 0.3253, Acc: 0.89\n",
      "Step [15600/50000], Loss: 0.1813, Acc: 0.95\n",
      "Step [15700/50000], Loss: 0.2140, Acc: 0.93\n",
      "Step [15800/50000], Loss: 0.3883, Acc: 0.87\n",
      "Step [15900/50000], Loss: 0.1514, Acc: 0.96\n",
      "Step [16000/50000], Loss: 0.3014, Acc: 0.93\n",
      "Step [16100/50000], Loss: 0.2986, Acc: 0.92\n",
      "Step [16200/50000], Loss: 0.3212, Acc: 0.94\n",
      "Step [16300/50000], Loss: 0.2343, Acc: 0.94\n",
      "Step [16400/50000], Loss: 0.2892, Acc: 0.96\n",
      "Step [16500/50000], Loss: 0.3697, Acc: 0.89\n",
      "Step [16600/50000], Loss: 0.3217, Acc: 0.94\n",
      "Step [16700/50000], Loss: 0.2715, Acc: 0.94\n",
      "Step [16800/50000], Loss: 0.1992, Acc: 0.94\n",
      "Step [16900/50000], Loss: 0.2174, Acc: 0.97\n",
      "Step [17000/50000], Loss: 0.2261, Acc: 0.94\n",
      "Step [17100/50000], Loss: 0.1634, Acc: 0.96\n",
      "Step [17200/50000], Loss: 0.3090, Acc: 0.93\n",
      "Step [17300/50000], Loss: 0.1632, Acc: 0.96\n",
      "Step [17400/50000], Loss: 0.2898, Acc: 0.91\n",
      "Step [17500/50000], Loss: 0.2315, Acc: 0.93\n",
      "Step [17600/50000], Loss: 0.3009, Acc: 0.89\n",
      "Step [17700/50000], Loss: 0.2396, Acc: 0.95\n",
      "Step [17800/50000], Loss: 0.2114, Acc: 0.93\n",
      "Step [17900/50000], Loss: 0.2200, Acc: 0.91\n",
      "Step [18000/50000], Loss: 0.2700, Acc: 0.94\n",
      "Step [18100/50000], Loss: 0.2647, Acc: 0.90\n",
      "Step [18200/50000], Loss: 0.2700, Acc: 0.92\n",
      "Step [18300/50000], Loss: 0.2044, Acc: 0.94\n",
      "Step [18400/50000], Loss: 0.2442, Acc: 0.92\n",
      "Step [18500/50000], Loss: 0.2737, Acc: 0.93\n",
      "Step [18600/50000], Loss: 0.2244, Acc: 0.95\n",
      "Step [18700/50000], Loss: 0.3009, Acc: 0.94\n",
      "Step [18800/50000], Loss: 0.2590, Acc: 0.92\n",
      "Step [18900/50000], Loss: 0.2462, Acc: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [19000/50000], Loss: 0.2679, Acc: 0.92\n",
      "Step [19100/50000], Loss: 0.2031, Acc: 0.91\n",
      "Step [19200/50000], Loss: 0.3118, Acc: 0.88\n",
      "Step [19300/50000], Loss: 0.2032, Acc: 0.95\n",
      "Step [19400/50000], Loss: 0.3927, Acc: 0.89\n",
      "Step [19500/50000], Loss: 0.2999, Acc: 0.92\n",
      "Step [19600/50000], Loss: 0.1275, Acc: 0.98\n",
      "Step [19700/50000], Loss: 0.1703, Acc: 0.94\n",
      "Step [19800/50000], Loss: 0.2165, Acc: 0.93\n",
      "Step [19900/50000], Loss: 0.4208, Acc: 0.89\n",
      "Step [20000/50000], Loss: 0.2030, Acc: 0.95\n",
      "Step [20100/50000], Loss: 0.3723, Acc: 0.89\n",
      "Step [20200/50000], Loss: 0.1659, Acc: 0.95\n",
      "Step [20300/50000], Loss: 0.1654, Acc: 0.93\n",
      "Step [20400/50000], Loss: 0.1170, Acc: 0.96\n",
      "Step [20500/50000], Loss: 0.2645, Acc: 0.95\n",
      "Step [20600/50000], Loss: 0.2268, Acc: 0.91\n",
      "Step [20700/50000], Loss: 0.2426, Acc: 0.91\n",
      "Step [20800/50000], Loss: 0.1867, Acc: 0.95\n",
      "Step [20900/50000], Loss: 0.3319, Acc: 0.92\n",
      "Step [21000/50000], Loss: 0.2269, Acc: 0.94\n",
      "Step [21100/50000], Loss: 0.2745, Acc: 0.88\n",
      "Step [21200/50000], Loss: 0.1546, Acc: 0.96\n",
      "Step [21300/50000], Loss: 0.3505, Acc: 0.87\n",
      "Step [21400/50000], Loss: 0.2539, Acc: 0.93\n",
      "Step [21500/50000], Loss: 0.2288, Acc: 0.93\n",
      "Step [21600/50000], Loss: 0.1446, Acc: 0.96\n",
      "Step [21700/50000], Loss: 0.1698, Acc: 0.94\n",
      "Step [21800/50000], Loss: 0.2189, Acc: 0.94\n",
      "Step [21900/50000], Loss: 0.2969, Acc: 0.93\n",
      "Step [22000/50000], Loss: 0.1914, Acc: 0.95\n",
      "Step [22100/50000], Loss: 0.2370, Acc: 0.94\n",
      "Step [22200/50000], Loss: 0.1940, Acc: 0.96\n",
      "Step [22300/50000], Loss: 0.2636, Acc: 0.92\n",
      "Step [22400/50000], Loss: 0.2238, Acc: 0.94\n",
      "Step [22500/50000], Loss: 0.2518, Acc: 0.91\n",
      "Step [22600/50000], Loss: 0.2823, Acc: 0.93\n",
      "Step [22700/50000], Loss: 0.2351, Acc: 0.95\n",
      "Step [22800/50000], Loss: 0.1688, Acc: 0.96\n",
      "Step [22900/50000], Loss: 0.1712, Acc: 0.95\n",
      "Step [23000/50000], Loss: 0.1704, Acc: 0.96\n",
      "Step [23100/50000], Loss: 0.1883, Acc: 0.94\n",
      "Step [23200/50000], Loss: 0.1644, Acc: 0.96\n",
      "Step [23300/50000], Loss: 0.2329, Acc: 0.93\n",
      "Step [23400/50000], Loss: 0.1405, Acc: 0.94\n",
      "Step [23500/50000], Loss: 0.1618, Acc: 0.96\n",
      "Step [23600/50000], Loss: 0.3753, Acc: 0.90\n",
      "Step [23700/50000], Loss: 0.2159, Acc: 0.94\n",
      "Step [23800/50000], Loss: 0.2666, Acc: 0.92\n",
      "Step [23900/50000], Loss: 0.1643, Acc: 0.96\n",
      "Step [24000/50000], Loss: 0.2291, Acc: 0.93\n",
      "Step [24100/50000], Loss: 0.3323, Acc: 0.90\n",
      "Step [24200/50000], Loss: 0.2770, Acc: 0.94\n",
      "Step [24300/50000], Loss: 0.1634, Acc: 0.96\n",
      "Step [24400/50000], Loss: 0.1445, Acc: 0.93\n",
      "Step [24500/50000], Loss: 0.1528, Acc: 0.96\n",
      "Step [24600/50000], Loss: 0.1659, Acc: 0.96\n",
      "Step [24700/50000], Loss: 0.2521, Acc: 0.94\n",
      "Step [24800/50000], Loss: 0.3929, Acc: 0.91\n",
      "Step [24900/50000], Loss: 0.1404, Acc: 0.95\n",
      "Step [25000/50000], Loss: 0.1798, Acc: 0.94\n",
      "Step [25100/50000], Loss: 0.3080, Acc: 0.92\n",
      "Step [25200/50000], Loss: 0.1265, Acc: 0.97\n",
      "Step [25300/50000], Loss: 0.2294, Acc: 0.93\n",
      "Step [25400/50000], Loss: 0.1905, Acc: 0.96\n",
      "Step [25500/50000], Loss: 0.3390, Acc: 0.89\n",
      "Step [25600/50000], Loss: 0.2076, Acc: 0.95\n",
      "Step [25700/50000], Loss: 0.2053, Acc: 0.97\n",
      "Step [25800/50000], Loss: 0.2444, Acc: 0.91\n",
      "Step [25900/50000], Loss: 0.2503, Acc: 0.93\n",
      "Step [26000/50000], Loss: 0.1508, Acc: 0.94\n",
      "Step [26100/50000], Loss: 0.1919, Acc: 0.94\n",
      "Step [26200/50000], Loss: 0.1604, Acc: 0.95\n",
      "Step [26300/50000], Loss: 0.0705, Acc: 0.98\n",
      "Step [26400/50000], Loss: 0.2431, Acc: 0.93\n",
      "Step [26500/50000], Loss: 0.2707, Acc: 0.93\n",
      "Step [26600/50000], Loss: 0.1426, Acc: 0.96\n",
      "Step [26700/50000], Loss: 0.1460, Acc: 0.95\n",
      "Step [26800/50000], Loss: 0.1956, Acc: 0.96\n",
      "Step [26900/50000], Loss: 0.3711, Acc: 0.91\n",
      "Step [27000/50000], Loss: 0.1357, Acc: 0.98\n",
      "Step [27100/50000], Loss: 0.2281, Acc: 0.94\n",
      "Step [27200/50000], Loss: 0.2201, Acc: 0.91\n",
      "Step [27300/50000], Loss: 0.2764, Acc: 0.94\n",
      "Step [27400/50000], Loss: 0.1317, Acc: 0.96\n",
      "Step [27500/50000], Loss: 0.0942, Acc: 0.96\n",
      "Step [27600/50000], Loss: 0.1194, Acc: 0.95\n",
      "Step [27700/50000], Loss: 0.1350, Acc: 0.96\n",
      "Step [27800/50000], Loss: 0.1051, Acc: 0.98\n",
      "Step [27900/50000], Loss: 0.1717, Acc: 0.95\n",
      "Step [28000/50000], Loss: 0.1490, Acc: 0.97\n",
      "Step [28100/50000], Loss: 0.2093, Acc: 0.91\n",
      "Step [28200/50000], Loss: 0.2131, Acc: 0.91\n",
      "Step [28300/50000], Loss: 0.1740, Acc: 0.93\n",
      "Step [28400/50000], Loss: 0.3565, Acc: 0.88\n",
      "Step [28500/50000], Loss: 0.1321, Acc: 0.97\n",
      "Step [28600/50000], Loss: 0.1088, Acc: 0.95\n",
      "Step [28700/50000], Loss: 0.1455, Acc: 0.96\n",
      "Step [28800/50000], Loss: 0.2046, Acc: 0.92\n",
      "Step [28900/50000], Loss: 0.2306, Acc: 0.92\n",
      "Step [29000/50000], Loss: 0.2538, Acc: 0.95\n",
      "Step [29100/50000], Loss: 0.1408, Acc: 0.97\n",
      "Step [29200/50000], Loss: 0.2180, Acc: 0.92\n",
      "Step [29300/50000], Loss: 0.2396, Acc: 0.92\n",
      "Step [29400/50000], Loss: 0.1498, Acc: 0.97\n",
      "Step [29500/50000], Loss: 0.1872, Acc: 0.92\n",
      "Step [29600/50000], Loss: 0.1454, Acc: 0.96\n",
      "Step [29700/50000], Loss: 0.2931, Acc: 0.94\n",
      "Step [29800/50000], Loss: 0.2057, Acc: 0.92\n",
      "Step [29900/50000], Loss: 0.2781, Acc: 0.90\n",
      "Step [30000/50000], Loss: 0.1131, Acc: 0.98\n",
      "Step [30100/50000], Loss: 0.1330, Acc: 0.95\n",
      "Step [30200/50000], Loss: 0.2325, Acc: 0.93\n",
      "Step [30300/50000], Loss: 0.2146, Acc: 0.94\n",
      "Step [30400/50000], Loss: 0.2560, Acc: 0.94\n",
      "Step [30500/50000], Loss: 0.1087, Acc: 0.98\n",
      "Step [30600/50000], Loss: 0.1566, Acc: 0.95\n",
      "Step [30700/50000], Loss: 0.1699, Acc: 0.95\n",
      "Step [30800/50000], Loss: 0.1852, Acc: 0.95\n",
      "Step [30900/50000], Loss: 0.1360, Acc: 0.96\n",
      "Step [31000/50000], Loss: 0.2826, Acc: 0.94\n",
      "Step [31100/50000], Loss: 0.2107, Acc: 0.97\n",
      "Step [31200/50000], Loss: 0.2598, Acc: 0.94\n",
      "Step [31300/50000], Loss: 0.1667, Acc: 0.95\n",
      "Step [31400/50000], Loss: 0.2564, Acc: 0.92\n",
      "Step [31500/50000], Loss: 0.1318, Acc: 0.96\n",
      "Step [31600/50000], Loss: 0.2087, Acc: 0.95\n",
      "Step [31700/50000], Loss: 0.2532, Acc: 0.95\n",
      "Step [31800/50000], Loss: 0.2034, Acc: 0.96\n",
      "Step [31900/50000], Loss: 0.1677, Acc: 0.93\n",
      "Step [32000/50000], Loss: 0.2643, Acc: 0.95\n",
      "Step [32100/50000], Loss: 0.1406, Acc: 0.97\n",
      "Step [32200/50000], Loss: 0.1809, Acc: 0.96\n",
      "Step [32300/50000], Loss: 0.1356, Acc: 0.97\n",
      "Step [32400/50000], Loss: 0.2593, Acc: 0.89\n",
      "Step [32500/50000], Loss: 0.1563, Acc: 0.95\n",
      "Step [32600/50000], Loss: 0.2081, Acc: 0.94\n",
      "Step [32700/50000], Loss: 0.1232, Acc: 0.96\n",
      "Step [32800/50000], Loss: 0.1279, Acc: 0.96\n",
      "Step [32900/50000], Loss: 0.2110, Acc: 0.96\n",
      "Step [33000/50000], Loss: 0.1607, Acc: 0.95\n",
      "Step [33100/50000], Loss: 0.1198, Acc: 0.97\n",
      "Step [33200/50000], Loss: 0.1318, Acc: 0.98\n",
      "Step [33300/50000], Loss: 0.0871, Acc: 0.98\n",
      "Step [33400/50000], Loss: 0.1264, Acc: 0.96\n",
      "Step [33500/50000], Loss: 0.1518, Acc: 0.98\n",
      "Step [33600/50000], Loss: 0.1055, Acc: 0.98\n",
      "Step [33700/50000], Loss: 0.1122, Acc: 0.98\n",
      "Step [33800/50000], Loss: 0.0790, Acc: 0.98\n",
      "Step [33900/50000], Loss: 0.2784, Acc: 0.90\n",
      "Step [34000/50000], Loss: 0.1218, Acc: 0.98\n",
      "Step [34100/50000], Loss: 0.1459, Acc: 0.95\n",
      "Step [34200/50000], Loss: 0.1000, Acc: 0.99\n",
      "Step [34300/50000], Loss: 0.0671, Acc: 0.99\n",
      "Step [34400/50000], Loss: 0.1162, Acc: 0.96\n",
      "Step [34500/50000], Loss: 0.1713, Acc: 0.97\n",
      "Step [34600/50000], Loss: 0.1511, Acc: 0.94\n",
      "Step [34700/50000], Loss: 0.1957, Acc: 0.93\n",
      "Step [34800/50000], Loss: 0.2167, Acc: 0.95\n",
      "Step [34900/50000], Loss: 0.1131, Acc: 0.97\n",
      "Step [35000/50000], Loss: 0.1971, Acc: 0.95\n",
      "Step [35100/50000], Loss: 0.1847, Acc: 0.95\n",
      "Step [35200/50000], Loss: 0.0714, Acc: 0.99\n",
      "Step [35300/50000], Loss: 0.1773, Acc: 0.96\n",
      "Step [35400/50000], Loss: 0.2377, Acc: 0.97\n",
      "Step [35500/50000], Loss: 0.1559, Acc: 0.97\n",
      "Step [35600/50000], Loss: 0.2638, Acc: 0.92\n",
      "Step [35700/50000], Loss: 0.2089, Acc: 0.92\n",
      "Step [35800/50000], Loss: 0.1702, Acc: 0.96\n",
      "Step [35900/50000], Loss: 0.1889, Acc: 0.95\n",
      "Step [36000/50000], Loss: 0.1311, Acc: 0.97\n",
      "Step [36100/50000], Loss: 0.0997, Acc: 0.97\n",
      "Step [36200/50000], Loss: 0.2160, Acc: 0.95\n",
      "Step [36300/50000], Loss: 0.1957, Acc: 0.95\n",
      "Step [36400/50000], Loss: 0.1551, Acc: 0.94\n",
      "Step [36500/50000], Loss: 0.1545, Acc: 0.96\n",
      "Step [36600/50000], Loss: 0.1017, Acc: 0.98\n",
      "Step [36700/50000], Loss: 0.1230, Acc: 0.96\n",
      "Step [36800/50000], Loss: 0.1409, Acc: 0.96\n",
      "Step [36900/50000], Loss: 0.2311, Acc: 0.94\n",
      "Step [37000/50000], Loss: 0.1553, Acc: 0.94\n",
      "Step [37100/50000], Loss: 0.2012, Acc: 0.95\n",
      "Step [37200/50000], Loss: 0.0535, Acc: 1.00\n",
      "Step [37300/50000], Loss: 0.1091, Acc: 0.96\n",
      "Step [37400/50000], Loss: 0.1854, Acc: 0.96\n",
      "Step [37500/50000], Loss: 0.1566, Acc: 0.95\n",
      "Step [37600/50000], Loss: 0.1808, Acc: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [37700/50000], Loss: 0.1356, Acc: 0.95\n",
      "Step [37800/50000], Loss: 0.2596, Acc: 0.93\n",
      "Step [37900/50000], Loss: 0.2773, Acc: 0.94\n",
      "Step [38000/50000], Loss: 0.1568, Acc: 0.95\n",
      "Step [38100/50000], Loss: 0.1733, Acc: 0.94\n",
      "Step [38200/50000], Loss: 0.0969, Acc: 0.97\n",
      "Step [38300/50000], Loss: 0.0885, Acc: 0.96\n",
      "Step [38400/50000], Loss: 0.1053, Acc: 0.97\n",
      "Step [38500/50000], Loss: 0.1265, Acc: 0.97\n",
      "Step [38600/50000], Loss: 0.1126, Acc: 0.97\n",
      "Step [38700/50000], Loss: 0.1779, Acc: 0.94\n",
      "Step [38800/50000], Loss: 0.0966, Acc: 0.99\n",
      "Step [38900/50000], Loss: 0.1019, Acc: 0.97\n",
      "Step [39000/50000], Loss: 0.1765, Acc: 0.94\n",
      "Step [39100/50000], Loss: 0.0542, Acc: 1.00\n",
      "Step [39200/50000], Loss: 0.2043, Acc: 0.95\n",
      "Step [39300/50000], Loss: 0.2087, Acc: 0.94\n",
      "Step [39400/50000], Loss: 0.0576, Acc: 0.98\n",
      "Step [39500/50000], Loss: 0.1783, Acc: 0.94\n",
      "Step [39600/50000], Loss: 0.1845, Acc: 0.95\n",
      "Step [39700/50000], Loss: 0.1496, Acc: 0.95\n",
      "Step [39800/50000], Loss: 0.1212, Acc: 0.98\n",
      "Step [39900/50000], Loss: 0.0735, Acc: 0.99\n",
      "Step [40000/50000], Loss: 0.1795, Acc: 0.95\n",
      "Step [40100/50000], Loss: 0.1284, Acc: 0.97\n",
      "Step [40200/50000], Loss: 0.1411, Acc: 0.97\n",
      "Step [40300/50000], Loss: 0.1743, Acc: 0.95\n",
      "Step [40400/50000], Loss: 0.1643, Acc: 0.94\n",
      "Step [40500/50000], Loss: 0.2630, Acc: 0.92\n",
      "Step [40600/50000], Loss: 0.0997, Acc: 0.98\n",
      "Step [40700/50000], Loss: 0.1460, Acc: 0.96\n",
      "Step [40800/50000], Loss: 0.1557, Acc: 0.94\n",
      "Step [40900/50000], Loss: 0.1960, Acc: 0.96\n",
      "Step [41000/50000], Loss: 0.2211, Acc: 0.93\n",
      "Step [41100/50000], Loss: 0.1442, Acc: 0.95\n",
      "Step [41200/50000], Loss: 0.1769, Acc: 0.97\n",
      "Step [41300/50000], Loss: 0.1363, Acc: 0.96\n",
      "Step [41400/50000], Loss: 0.0549, Acc: 1.00\n",
      "Step [41500/50000], Loss: 0.1155, Acc: 0.97\n",
      "Step [41600/50000], Loss: 0.1090, Acc: 0.97\n",
      "Step [41700/50000], Loss: 0.1473, Acc: 0.96\n",
      "Step [41800/50000], Loss: 0.1635, Acc: 0.95\n",
      "Step [41900/50000], Loss: 0.1056, Acc: 0.99\n",
      "Step [42000/50000], Loss: 0.0759, Acc: 0.98\n",
      "Step [42100/50000], Loss: 0.1325, Acc: 0.95\n",
      "Step [42200/50000], Loss: 0.1673, Acc: 0.93\n",
      "Step [42300/50000], Loss: 0.0621, Acc: 0.98\n",
      "Step [42400/50000], Loss: 0.1288, Acc: 0.98\n",
      "Step [42500/50000], Loss: 0.0940, Acc: 0.96\n",
      "Step [42600/50000], Loss: 0.1179, Acc: 0.97\n",
      "Step [42700/50000], Loss: 0.2178, Acc: 0.94\n",
      "Step [42800/50000], Loss: 0.1858, Acc: 0.95\n",
      "Step [42900/50000], Loss: 0.1457, Acc: 0.97\n",
      "Step [43000/50000], Loss: 0.0893, Acc: 0.96\n",
      "Step [43100/50000], Loss: 0.0968, Acc: 0.97\n",
      "Step [43200/50000], Loss: 0.1788, Acc: 0.93\n",
      "Step [43300/50000], Loss: 0.1510, Acc: 0.92\n",
      "Step [43400/50000], Loss: 0.1501, Acc: 0.93\n",
      "Step [43500/50000], Loss: 0.1162, Acc: 0.96\n",
      "Step [43600/50000], Loss: 0.1313, Acc: 0.97\n",
      "Step [43700/50000], Loss: 0.1244, Acc: 0.98\n",
      "Step [43800/50000], Loss: 0.1704, Acc: 0.97\n",
      "Step [43900/50000], Loss: 0.2155, Acc: 0.95\n",
      "Step [44000/50000], Loss: 0.1912, Acc: 0.94\n",
      "Step [44100/50000], Loss: 0.1583, Acc: 0.94\n",
      "Step [44200/50000], Loss: 0.1989, Acc: 0.92\n",
      "Step [44300/50000], Loss: 0.2110, Acc: 0.94\n",
      "Step [44400/50000], Loss: 0.1345, Acc: 0.93\n",
      "Step [44500/50000], Loss: 0.0906, Acc: 0.97\n",
      "Step [44600/50000], Loss: 0.1164, Acc: 0.96\n",
      "Step [44700/50000], Loss: 0.1543, Acc: 0.95\n",
      "Step [44800/50000], Loss: 0.0864, Acc: 0.97\n",
      "Step [44900/50000], Loss: 0.1298, Acc: 0.96\n",
      "Step [45000/50000], Loss: 0.1425, Acc: 0.97\n",
      "Step [45100/50000], Loss: 0.1937, Acc: 0.97\n",
      "Step [45200/50000], Loss: 0.1676, Acc: 0.95\n",
      "Step [45300/50000], Loss: 0.1622, Acc: 0.95\n",
      "Step [45400/50000], Loss: 0.1777, Acc: 0.96\n",
      "Step [45500/50000], Loss: 0.1274, Acc: 0.98\n",
      "Step [45600/50000], Loss: 0.2769, Acc: 0.94\n",
      "Step [45700/50000], Loss: 0.1081, Acc: 0.98\n",
      "Step [45800/50000], Loss: 0.1958, Acc: 0.95\n",
      "Step [45900/50000], Loss: 0.0833, Acc: 0.97\n",
      "Step [46000/50000], Loss: 0.2636, Acc: 0.93\n",
      "Step [46100/50000], Loss: 0.0706, Acc: 0.98\n",
      "Step [46200/50000], Loss: 0.1410, Acc: 0.96\n",
      "Step [46300/50000], Loss: 0.1495, Acc: 0.98\n",
      "Step [46400/50000], Loss: 0.2037, Acc: 0.96\n",
      "Step [46500/50000], Loss: 0.1288, Acc: 0.96\n",
      "Step [46600/50000], Loss: 0.1964, Acc: 0.95\n",
      "Step [46700/50000], Loss: 0.0660, Acc: 0.99\n",
      "Step [46800/50000], Loss: 0.2480, Acc: 0.97\n",
      "Step [46900/50000], Loss: 0.1596, Acc: 0.97\n",
      "Step [47000/50000], Loss: 0.1362, Acc: 0.95\n",
      "Step [47100/50000], Loss: 0.1122, Acc: 0.97\n",
      "Step [47200/50000], Loss: 0.0799, Acc: 0.99\n",
      "Step [47300/50000], Loss: 0.1021, Acc: 0.98\n",
      "Step [47400/50000], Loss: 0.1558, Acc: 0.96\n",
      "Step [47500/50000], Loss: 0.1957, Acc: 0.94\n",
      "Step [47600/50000], Loss: 0.0974, Acc: 0.99\n",
      "Step [47700/50000], Loss: 0.0744, Acc: 0.99\n",
      "Step [47800/50000], Loss: 0.0819, Acc: 0.96\n",
      "Step [47900/50000], Loss: 0.1558, Acc: 0.95\n",
      "Step [48000/50000], Loss: 0.1441, Acc: 0.98\n",
      "Step [48100/50000], Loss: 0.1245, Acc: 0.97\n",
      "Step [48200/50000], Loss: 0.1258, Acc: 0.99\n",
      "Step [48300/50000], Loss: 0.1283, Acc: 0.98\n",
      "Step [48400/50000], Loss: 0.1024, Acc: 0.99\n",
      "Step [48500/50000], Loss: 0.1357, Acc: 0.96\n",
      "Step [48600/50000], Loss: 0.2039, Acc: 0.93\n",
      "Step [48700/50000], Loss: 0.1238, Acc: 0.95\n",
      "Step [48800/50000], Loss: 0.1454, Acc: 0.96\n",
      "Step [48900/50000], Loss: 0.1100, Acc: 0.96\n",
      "Step [49000/50000], Loss: 0.1655, Acc: 0.96\n",
      "Step [49100/50000], Loss: 0.1658, Acc: 0.94\n",
      "Step [49200/50000], Loss: 0.1347, Acc: 0.97\n",
      "Step [49300/50000], Loss: 0.1291, Acc: 0.96\n",
      "Step [49400/50000], Loss: 0.1016, Acc: 0.97\n",
      "Step [49500/50000], Loss: 0.1180, Acc: 0.97\n",
      "Step [49600/50000], Loss: 0.2404, Acc: 0.92\n",
      "Step [49700/50000], Loss: 0.1864, Acc: 0.96\n",
      "Step [49800/50000], Loss: 0.0704, Acc: 1.00\n",
      "Step [49900/50000], Loss: 0.0792, Acc: 0.98\n",
      "Step [50000/50000], Loss: 0.1406, Acc: 0.96\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "for step in range(total_step):\n",
    "    \n",
    "    # 重置迭代器\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # 获取图像和标签\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 计算准确率\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        该部分为保存 TensorBoard 日志信息                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        # 日志输出标量信息（scalar summary）\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "        # 2. Log values and gradients of the parameters (histogram summary)\n",
    "        # 日志输出参数值和梯度（histogram summary)\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "            logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "        # 3. Log training images (image summary)\n",
    "        # 日志输出图像(image summary)\n",
    "        info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            logger.image_summary(tag, images, step+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用TensorBoard进行可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过训练后，日志信息保存在`./logs`文件夹下。运行命令进行可视化，\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir='./logs' --port=6006\n",
    "```\n",
    "\n",
    "然后打开本地浏览器，打开` http://localhost:6006/ `就能看到了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标量Scalar\n",
    "\n",
    "![标量Scalar](TensorBoard_Scalar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片Image\n",
    "\n",
    "![图片Image](TensorBoard_Image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直方图Histogram\n",
    "\n",
    "![直方图Histogram](TensorBoard_Histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 致谢\n",
    "\n",
    "[yunjey的Pytorch](https://github.com/yunjey/pytorch-tutorial)总算学完了，既初步掌握了Pytorch，又把深度学习中的重要概念过了一遍，收获多多。\n",
    "\n",
    "大神的代码简洁无比，非常感谢。\n",
    "\n",
    "学完Pytorch，后面应该盯着目标检测去了，至少掌握了一门深度学习框架，实践起来应该会顺手很多。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
